{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP - Análise Exploratória e Pré-processamento de Dados\n",
    "## Dataset: Student Performance\n",
    "\n",
    "**Autor**: [andre luiz marques serrano]\n",
    "**Data**: Junho 2025\n",
    "**Fonte**: UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definição do Problema\n",
    "\n",
    "### Contexto\n",
    "\n",
    "Este projeto tem como objetivo realizar uma análise exploratória completa e pré-processamento de dados do dataset \"Student Performance\" do UCI Machine Learning Repository. O dataset contém informações sobre o desempenho acadêmico de estudantes do ensino médio de duas escolas portuguesas, incluindo dados demográficos, sociais, escolares e notas finais.\n",
    "\n",
    "**Problema**: Predizer o desempenho acadêmico final (G3) dos estudantes com base em características pessoais, familiares e escolares.\n",
    "\n",
    "**Tipo de Problema**: Este é um problema de **aprendizado supervisionado**, podendo ser abordado tanto como:\n",
    "- **Regressão**: Predizer a nota final exata (0-20)\n",
    "- **Classificação**: Predizer categorias de desempenho (ex: baixo, médio, alto)\n",
    "\n",
    "### Premissas e Hipóteses\n",
    "\n",
    "1. **Premissa**: Fatores socioeconômicos, familiares e comportamentais influenciam significativamente o desempenho acadêmico\n",
    "2. **Hipótese 1**: Estudantes com maior suporte familiar (famsup=yes) tendem a ter melhor desempenho\n",
    "3. **Hipótese 2**: Tempo de estudo (studytime) está positivamente correlacionado com as notas\n",
    "4. **Hipótese 3**: Consumo de álcool (Dalc, Walc) está negativamente correlacionado com o desempenho\n",
    "5. **Hipótese 4**: Estudantes que querem ensino superior (higher=yes) têm melhor desempenho\n",
    "\n",
    "### Restrições e Condições para Seleção dos Dados\n",
    "\n",
    "1. **Dataset escolhido**: Student Performance do UCI ML Repository\n",
    "2. **Critério de seleção**: Dataset não utilizado nas disciplinas anteriores\n",
    "3. **Foco**: Utilizaremos o dataset de **Matemática** (student-mat.csv) por ser mais desafiador\n",
    "4. **Tamanho**: 395 estudantes com 33 variáveis (30 features + 3 notas)\n",
    "5. **Qualidade**: Dataset sem valores faltantes, facilitando a análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição dos Atributos\n",
    "\n",
    "#### Variáveis Demográficas:\n",
    "- **school**: Escola do estudante (GP - Gabriel Pereira ou MS - Mousinho da Silveira)\n",
    "- **sex**: Sexo (F - feminino, M - masculino)\n",
    "- **age**: Idade (15-22 anos)\n",
    "- **address**: Tipo de endereço (U - urbano, R - rural)\n",
    "\n",
    "#### Variáveis Familiares:\n",
    "- **famsize**: Tamanho da família (LE3 ≤ 3, GT3 > 3)\n",
    "- **Pstatus**: Status de coabitação dos pais (T - juntos, A - separados)\n",
    "- **Medu**: Educação da mãe (0-4, sendo 0=nenhuma, 4=superior)\n",
    "- **Fedu**: Educação do pai (0-4, sendo 0=nenhuma, 4=superior)\n",
    "- **Mjob**: Trabalho da mãe (teacher, health, services, at_home, other)\n",
    "- **Fjob**: Trabalho do pai (teacher, health, services, at_home, other)\n",
    "- **guardian**: Responsável (mother, father, other)\n",
    "- **famrel**: Qualidade das relações familiares (1-5)\n",
    "- **famsup**: Suporte educacional familiar (yes/no)\n",
    "\n",
    "#### Variáveis Escolares:\n",
    "- **reason**: Razão para escolher a escola (home, reputation, course, other)\n",
    "- **traveltime**: Tempo de viagem casa-escola (1-4)\n",
    "- **studytime**: Tempo de estudo semanal (1-4)\n",
    "- **failures**: Número de reprovações passadas (0-4)\n",
    "- **schoolsup**: Suporte educacional extra (yes/no)\n",
    "- **paid**: Aulas extras pagas (yes/no)\n",
    "- **activities**: Atividades extracurriculares (yes/no)\n",
    "- **nursery**: Frequentou creche (yes/no)\n",
    "- **higher**: Quer ensino superior (yes/no)\n",
    "- **internet**: Acesso à internet em casa (yes/no)\n",
    "\n",
    "#### Variáveis Sociais/Comportamentais:\n",
    "- **romantic**: Em relacionamento romântico (yes/no)\n",
    "- **freetime**: Tempo livre após escola (1-5)\n",
    "- **goout**: Sair com amigos (1-5)\n",
    "- **Dalc**: Consumo de álcool em dias úteis (1-5)\n",
    "- **Walc**: Consumo de álcool nos fins de semana (1-5)\n",
    "- **health**: Estado de saúde atual (1-5)\n",
    "- **absences**: Número de faltas escolares (0-93)\n",
    "\n",
    "#### Variáveis Target:\n",
    "- **G1**: Nota do primeiro período (0-20)\n",
    "- **G2**: Nota do segundo período (0-20)\n",
    "- **G3**: **Nota final (0-20) - VARIÁVEL TARGET PRINCIPAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importação de Bibliotecas e Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurações para visualização\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações do pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   
"source": [
    "# Carregamento do dataset\n",
    "# URL do dataset no GitHub (será atualizada após upload)\n",
    "#url = \"https://raw.githubusercontent.com/[SEU_USUARIO]/[SEU_REPOSITORIO]/main/student-mat.csv\"\n",
    "\n",
    "# carregamos localmente\n",
    "#df = pd.read_csv('student-mat.csv', sep=';')\n",
    "#\n",
    "#print(f\"Dataset carregado com sucesso!\")\n",
    "# print(f\"Dimensões: {df.shape[0]} linhas e {df.shape[1]} colunas\")"


#Instalar o pacote ucimlrepo 
pip instalar ucimlrepo

#Importe o conjunto de dados para seu código 
de ucimlrepo importar fetch_ucirepo
  
# buscar conjunto de dados
desempenho_do_aluno = fetch_ucirepo(id=320)
  
# dados (como dataframes do pandas)
X = dados_de_desempenho_do_aluno.recursos
y = dados_desempenho_do_aluno.alvos
  
# metadados
imprimir(desempenho_do_aluno.metadados)
  
# informação variável
imprimir(desempenho_do_aluno.variáveis)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise Exploratória de Dados\n",
    "\n",
    "### 3.1 Estatísticas Descritivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações gerais sobre o dataset\n",
    "print(\"=== INFORMAÇÕES GERAIS DO DATASET ===\")\n",
    "print(f\"Número de instâncias: {df.shape[0]}\")\n",
    "print(f\"Número de atributos: {df.shape[1]}\")\n",
    "print(f\"\\nTipos de dados:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiras linhas do dataset\n",
    "print(\"=== PRIMEIRAS 5 LINHAS DO DATASET ===\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n=== INFORMAÇÕES DETALHADAS ===\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de valores faltantes\n",
    "print(\"=== VERIFICAÇÃO DE VALORES FALTANTES ===\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Total de valores faltantes: {missing_values.sum()}\")\n",
    "\n",
    "if missing_values.sum() > 0:\n",
    "    print(\"\\nVariáveis com valores faltantes:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"✅ Excelente! Não há valores faltantes no dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificação de tipos de variáveis\n",
    "numeric_vars = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_vars = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"=== TIPOS DE VARIÁVEIS ===\")\n",
    "print(f\"Variáveis numéricas ({len(numeric_vars)}): {numeric_vars}\")\n",
    "print(f\"\\nVariáveis categóricas ({len(categorical_vars)}): {categorical_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas para variáveis numéricas\n",
    "print(\"=== ESTATÍSTICAS DESCRITIVAS - VARIÁVEIS NUMÉRICAS ===\")\n",
    "display(df[numeric_vars].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise das Estatísticas Descritivas:**\n",
    "\n",
    "Com base nas estatísticas descritivas das variáveis numéricas, podemos observar:\n",
    "\n",
    "1. **Idade (age)**: Varia de 15 a 22 anos, com média de aproximadamente 16.7 anos\n",
    "2. **Educação dos pais (Medu, Fedu)**: Escala de 0-4, com médias próximas a 2.5\n",
    "3. **Notas (G1, G2, G3)**: Escala de 0-20, sendo G3 nossa variável target principal\n",
    "4. **Faltas (absences)**: Grande variação (0-93), indicando possível presença de outliers\n",
    "5. **Variáveis comportamentais**: Escalas de 1-5 para freetime, goout, famrel, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das variáveis categóricas\n",
    "print(\"=== ANÁLISE DAS VARIÁVEIS CATEGÓRICAS ===\")\n",
    "for var in categorical_vars:\n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"Valores únicos: {df[var].nunique()}\")\n",
    "    print(f\"Categorias: {df[var].unique()}\")\n",
    "    print(f\"Distribuição:\")\n",
    "    print(df[var].value_counts())\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualizações e Distribuições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição da variável target (G3)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['G3'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribuição da Nota Final (G3)')\n",
    "plt.xlabel('Nota Final (G3)')\n",
    "plt.ylabel('Frequência')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df['G3'])\n",
    "plt.title('Boxplot da Nota Final (G3)')\n",
    "plt.ylabel('Nota Final (G3)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Estatísticas da variável target (G3):\")\n",
    "print(f\"Média: {df['G3'].mean():.2f}\")\n",
    "print(f\"Mediana: {df['G3'].median():.2f}\")\n",
    "print(f\"Desvio padrão: {df['G3'].std():.2f}\")\n",
    "print(f\"Mínimo: {df['G3'].min()}\")\n",
    "print(f\"Máximo: {df['G3'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise da Distribuição da Variável Target:**\n",
    "\n",
    "A distribuição da nota final (G3) mostra [análise será completada após execução do código]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das principais variáveis numéricas\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "important_numeric = ['age', 'Medu', 'Fedu', 'studytime', 'failures', 'absences']\n",
    "\n",
    "for i, var in enumerate(important_numeric):\n",
    "    axes[i].hist(df[var], bins=15, edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(f'Distribuição de {var}')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('Frequência')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de correlação entre variáveis numéricas\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df[numeric_vars].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Matriz de Correlação - Variáveis Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlações mais fortes com G3\n",
    "g3_correlations = correlation_matrix['G3'].abs().sort_values(ascending=False)\n",
    "print(\"=== CORRELAÇÕES MAIS FORTES COM G3 ===\")\n",
    "print(g3_correlations[1:])  # Excluindo a correlação de G3 consigo mesmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Análise de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição das principais variáveis categóricas\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "important_categorical = ['school', 'sex', 'address', 'famsup', 'higher', 'internet']\n",
    "\n",
    "for i, var in enumerate(important_categorical):\n",
    "    df[var].value_counts().plot(kind='bar', ax=axes[i])\n",
    "    axes[i].set_title(f'Distribuição de {var}')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('Frequência')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise da relação entre variáveis categóricas e G3\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(important_categorical):\n",
    "    df.boxplot(column='G3', by=var, ax=axes[i])\n",
    "    axes[i].set_title(f'G3 por {var}')\n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('G3')\n",
    "\n",
    "plt.suptitle('')  # Remove o título automático\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pré-processamento de Dados\n",
    "\n",
    "### 4.1 Tratamento de Valores Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como não há valores faltantes, vamos prosseguir para outras transformações\n",
    "print(\"✅ Não há valores faltantes para tratar.\")\n",
    "print(\"Prosseguindo para outras transformações...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Encoding de Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma cópia do dataset para transformações\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Label Encoding para variáveis binárias\n",
    "binary_vars = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'schoolsup', \n",
    "               'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "\n",
    "le = LabelEncoder()\n",
    "for var in binary_vars:\n",
    "    if var in df_processed.columns:\n",
    "        df_processed[var + '_encoded'] = le.fit_transform(df_processed[var])\n",
    "        print(f\"{var}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "print(\"\\nLabel encoding concluído para variáveis binárias.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding para variáveis categóricas com múltiplas categorias\n",
    "multi_categorical = ['Mjob', 'Fjob', 'reason', 'guardian']\n",
    "\n",
    "for var in multi_categorical:\n",
    "    if var in df_processed.columns:\n",
    "        dummies = pd.get_dummies(df_processed[var], prefix=var)\n",
    "        df_processed = pd.concat([df_processed, dummies], axis=1)\n",
    "        print(f\"One-hot encoding criado para {var}: {list(dummies.columns)}\")\n",
    "\n",
    "print(f\"\\nDataset após encoding: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Normalização e Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando variáveis numéricas para normalização\n",
    "numeric_to_scale = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures',\n",
    "                   'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
    "\n",
    "# Padronização (Z-score)\n",
    "scaler = StandardScaler()\n",
    "df_processed[['scaled_' + var for var in numeric_to_scale]] = scaler.fit_transform(df_processed[numeric_to_scale])\n",
    "\n",
    "print(\"Padronização concluída para variáveis numéricas.\")\n",
    "print(f\"Variáveis padronizadas: {['scaled_' + var for var in numeric_to_scale]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Criação de Novas Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando features derivadas\n",
    "df_processed['parents_edu_avg'] = (df_processed['Medu'] + df_processed['Fedu']) / 2\n",
    "df_processed['alcohol_total'] = df_processed['Dalc'] + df_processed['Walc']\n",
    "df_processed['social_score'] = df_processed['freetime'] + df_processed['goout']\n",
    "df_processed['support_total'] = df_processed['schoolsup_encoded'] + df_processed['famsup_encoded']\n",
    "\n",
    "# Categorização da nota final\n",
    "def categorize_grade(grade):\n",
    "    if grade < 10:\n",
    "        return 'Baixo'\n",
    "    elif grade < 15:\n",
    "        return 'Médio'\n",
    "    else:\n",
    "        return 'Alto'\n",
    "\n",
    "df_processed['G3_category'] = df_processed['G3'].apply(categorize_grade)\n",
    "\n",
    "print(\"Novas features criadas:\")\n",
    "print(\"- parents_edu_avg: Média da educação dos pais\")\n",
    "print(\"- alcohol_total: Consumo total de álcool\")\n",
    "print(\"- social_score: Score social (freetime + goout)\")\n",
    "print(\"- support_total: Total de suporte (escolar + familiar)\")\n",
    "print(\"- G3_category: Categorização da nota final\")\n",
    "\n",
    "print(f\"\\nDistribuição de G3_category:\")\n",
    "print(df_processed['G3_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Detecção e Tratamento de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecção de outliers usando IQR\n",
    "def detect_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Analisando outliers em variáveis importantes\n",
    "outlier_vars = ['age', 'absences', 'G1', 'G2', 'G3']\n",
    "\n",
    "for var in outlier_vars:\n",
    "    outliers, lower, upper = detect_outliers_iqr(df_processed, var)\n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"Limites: [{lower:.2f}, {upper:.2f}]\")\n",
    "    print(f\"Outliers detectados: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"Valores outliers: {sorted(outliers[var].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização de outliers\n",
    "fig, axes = plt.subplots(1, len(outlier_vars), figsize=(20, 4))\n",
    "\n",
    "for i, var in enumerate(outlier_vars):\n",
    "    axes[i].boxplot(df_processed[var])\n",
    "    axes[i].set_title(f'Outliers em {var}')\n",
    "    axes[i].set_ylabel(var)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Preparação dos Datasets Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando diferentes versões do dataset para diferentes abordagens\n",
    "\n",
    "# 1. Dataset original (apenas limpeza básica)\n",
    "df_original = df.copy()\n",
    "\n",
    "# 2. Dataset com encoding básico\n",
    "feature_cols_basic = [col for col in df_processed.columns if col.endswith('_encoded')] + numeric_vars[:-3]  # Excluindo G1, G2, G3\n",
    "df_basic = df_processed[feature_cols_basic + ['G3']].copy()\n",
    "\n",
    "# 3. Dataset com features padronizadas\n",
    "feature_cols_scaled = [col for col in df_processed.columns if col.startswith('scaled_')] + [col for col in df_processed.columns if col.endswith('_encoded')]\n",
    "df_scaled = df_processed[feature_cols_scaled + ['G3']].copy()\n",
    "\n",
    "# 4. Dataset completo com todas as transformações\n",
    "feature_cols_complete = (feature_cols_scaled + \n",
    "                        [col for col in df_processed.columns if any(prefix in col for prefix in ['Mjob_', 'Fjob_', 'reason_', 'guardian_'])] +\n",
    "                        ['parents_edu_avg', 'alcohol_total', 'social_score', 'support_total'])\n",
    "df_complete = df_processed[feature_cols_complete + ['G3', 'G3_category']].copy()\n",
    "\n",
    "print(\"=== DATASETS PREPARADOS ===\")\n",
    "print(f\"1. Dataset Original: {df_original.shape}\")\n",
    "print(f\"2. Dataset Básico: {df_basic.shape}\")\n",
    "print(f\"3. Dataset Padronizado: {df_scaled.shape}\")\n",
    "print(f\"4. Dataset Completo: {df_complete.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise Final e Insights\n",
    "\n",
    "### 5.1 Resumo das Transformações Realizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMO DAS TRANSFORMAÇÕES REALIZADAS ===\")\n",
    "print(\"\\n1. TRATAMENTO DE VALORES FALTANTES:\")\n",
    "print(\"   ✅ Não foram encontrados valores faltantes\")\n",
    "\n",
    "print(\"\\n2. ENCODING DE VARIÁVEIS CATEGÓRICAS:\")\n",
    "print(f\"   ✅ Label encoding aplicado a {len(binary_vars)} variáveis binárias\")\n",
    "print(f\"   ✅ One-hot encoding aplicado a {len(multi_categorical)} variáveis categóricas\")\n",
    "\n",
    "print(\"\\n3. NORMALIZAÇÃO E PADRONIZAÇÃO:\")\n",
    "print(f\"   ✅ Padronização Z-score aplicada a {len(numeric_to_scale)} variáveis numéricas\")\n",
    "\n",
    "print(\"\\n4. CRIAÇÃO DE NOVAS FEATURES:\")\n",
    "print(\"   ✅ parents_edu_avg: Média da educação dos pais\")\n",
    "print(\"   ✅ alcohol_total: Consumo total de álcool\")\n",
    "print(\"   ✅ social_score: Score social\")\n",
    "print(\"   ✅ support_total: Total de suporte\")\n",
    "print(\"   ✅ G3_category: Categorização da variável target\")\n",
    "\n",
    "print(\"\\n5. DETECÇÃO DE OUTLIERS:\")\n",
    "print(\"   ✅ Análise de outliers realizada usando método IQR\")\n",
    "print(\"   ✅ Outliers identificados mas mantidos para preservar informação\")\n",
    "\n",
    "print(\"\\n6. PREPARAÇÃO DE DATASETS:\")\n",
    "print(\"   ✅ 4 versões diferentes do dataset preparadas\")\n",
    "print(\"   ✅ Datasets prontos para modelagem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Principais Insights Descobertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise final de correlações e insights\n",
    "print(\"=== PRINCIPAIS INSIGHTS DESCOBERTOS ===\")\n",
    "\n",
    "# Correlações mais importantes com G3\n",
    "important_correlations = df_processed[['G1', 'G2', 'G3', 'failures', 'studytime', \n",
    "                                     'higher_encoded', 'famsup_encoded', 'absences']].corr()['G3'].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\n1. CORRELAÇÕES MAIS FORTES COM A NOTA FINAL (G3):\")\n",
    "for var, corr in important_correlations[1:6].items():  # Top 5 excluindo G3\n",
    "    print(f\"   • {var}: {corr:.3f}\")\n",
    "\n",
    "# Análise por categorias\n",
    "print(\"\\n2. DISTRIBUIÇÃO DE PERFORMANCE:\")\n",
    "performance_dist = df_processed['G3_category'].value_counts(normalize=True) * 100\n",
    "for category, percentage in performance_dist.items():\n",
    "    print(f\"   • {category}: {percentage:.1f}%\")\n",
    "\n",
    "# Médias por grupos importantes\n",
    "print(\"\\n3. DIFERENÇAS DE PERFORMANCE POR GRUPOS:\")\n",
    "print(f\"   • Com suporte familiar: {df_processed[df_processed['famsup_encoded']==1]['G3'].mean():.2f}\")\n",
    "print(f\"   • Sem suporte familiar: {df_processed[df_processed['famsup_encoded']==0]['G3'].mean():.2f}\")\n",
    "print(f\"   • Quer ensino superior: {df_processed[df_processed['higher_encoded']==1]['G3'].mean():.2f}\")\n",
    "print(f\"   • Não quer ensino superior: {df_processed[df_processed['higher_encoded']==0]['G3'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Recomendações para Próximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RECOMENDAÇÕES PARA PRÓXIMOS PASSOS ===\")\n",
    "print(\"\\n1. MODELAGEM:\")\n",
    "print(\"   • Testar modelos de regressão para predição da nota exata\")\n",
    "print(\"   • Testar modelos de classificação para categorias de performance\")\n",
    "print(\"   • Comparar performance entre os diferentes datasets preparados\")\n",
    "\n",
    "print(\"\\n2. FEATURE ENGINEERING ADICIONAL:\")\n",
    "print(\"   • Criar interações entre variáveis importantes\")\n",
    "print(\"   • Testar transformações não-lineares\")\n",
    "print(\"   • Aplicar técnicas de seleção de features\")\n",
    "\n",
    "print(\"\\n3. VALIDAÇÃO:\")\n",
    "print(\"   • Implementar validação cruzada\")\n",
    "print(\"   • Testar diferentes métricas de avaliação\")\n",
    "print(\"   • Analisar importância das features\")\n",
    "\n",
    "print(\"\\n4. INTERPRETABILIDADE:\")\n",
    "print(\"   • Usar SHAP ou LIME para explicar predições\")\n",
    "print(\"   • Criar visualizações interativas\")\n",
    "print(\"   • Desenvolver insights acionáveis para educadores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusão\n",
    "\n",
    "Este projeto realizou uma análise exploratória completa e pré-processamento do dataset Student Performance, seguindo todas as etapas da metodologia de ciência de dados:\n",
    "\n",
    "### Principais Realizações:\n",
    "\n",
    "1. **Definição clara do problema**: Estabelecemos o objetivo de predizer performance acadêmica\n",
    "2. **Análise exploratória abrangente**: Compreendemos a estrutura e características dos dados\n",
    "3. **Pré-processamento robusto**: Aplicamos múltiplas técnicas de transformação\n",
    "4. **Criação de features**: Desenvolvemos variáveis derivadas relevantes\n",
    "5. **Preparação para modelagem**: Criamos diferentes versões do dataset\n",
    "\n",
    "### Dataset Final:\n",
    "- **Instâncias**: 395 estudantes\n",
    "- **Features originais**: 33\n",
    "- **Features após processamento**: 50+\n",
    "- **Qualidade**: Sem valores faltantes, outliers identificados\n",
    "- **Pronto para**: Modelagem de regressão e classificação\n",
    "\n",
    "### Próximos Passos:\n",
    "O dataset está preparado para a fase de modelagem, onde poderemos testar diferentes algoritmos de machine learning para predizer o desempenho acadêmico dos estudantes.\n",
    "\n",
    "---\n",
    "\n",
    "**Referência**: Cortez, P. & Silva, A. (2008). Using data mining to predict secondary school student performance. Proceedings of 5th Annual Future Business Technology Conference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

